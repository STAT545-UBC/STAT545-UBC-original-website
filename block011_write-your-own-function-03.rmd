---
title: "Write your own R functions, part 3"
output:
  html_document:
    toc: true
    toc_depth: 3
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE, collapse = TRUE)
```

### Where were we? Where are we going?

In [part 2]() we generalized our first R function so it could take the difference between any two quantiles of a numeric vector. We also set default values for the underlying probabilities, so that, by default, we compute the max minus the min.

In this part, we tackle `NA`s, the special argument `...` and formal testing.

### Load the Gapminder data

As usual, load the Gapminder excerpt.

```{r}
gDat <- read.delim("gapminderDataFiveYear.txt")
str(gDat)
## or do this if the file isn't lying around already
## gd_url <- "http://tiny.cc/gapminder"
## gDat <- read.delim(gd_url)
```

### Load assertthat and our qdiff function

We'll keep using `assert_that()` to check that `x` is numeric and we'll want our previous function around as a baseline.

```{r}
library(assertthat)
qdiff4 <- function(x, probs = c(0, 1)) {
  assert_that(is.numeric(x))
  the_quantiles <- quantile(x, probs)
  return(max(the_quantiles) - min(the_quantiles))
}
```

### Be proactive about `NA`s

I am being gentle by letting you practice with the Gapminder data. In real life, you will be plagued by missing data. If you are lucky, it will be properly indicated by the special value `NA`. Many built-in R functions have an `na.rm =` argument through which you can specify how you want to handle `NA`s. Typically the default value is `na.rm = FALSE` and typical default behavior is to either let `NA`s propagate or to raise an error. Let's see how `quantile()` handles `NA`s:

```{r}
z <- gDat$lifeExp
z[3] <- NA
quantile(gDat$lifeExp)
quantile(z)
quantile(z, na.rm = TRUE)
```

So `quantile()` simply will not operate in the presence of `NA`s unless `na.rm = TRUE`. How shall we modify our function?

If we wanted to hardwire `na.rm = TRUE`, we could. Focus on our call to `quantile()` inside our function definition.

```{r}
qdiff5 <- function(x, probs = c(0, 1)) {
  assert_that(is.numeric(x))
  the_quantiles <- quantile(x, probs, na.rm = TRUE)
  return(max(the_quantiles) - min(the_quantiles))
}
qdiff5(gDat$lifeExp)
qdiff5(z)
```

This works but it is dangerous to invert the default behavior of a well-known built-in function and to provide the user with no way to override this.

We could add an `na.rm =` argument to our own function. We might even enforce our preferred default -- but at least we're giving the user a way to control the behavior around `NA`s.

```{r}
qdiff6 <- function(x, probs = c(0, 1), na.rm = TRUE) {
  assert_that(is.numeric(x))
  the_quantiles <- quantile(x, probs, na.rm = na.rm)
  return(max(the_quantiles) - min(the_quantiles))
}
qdiff6(gDat$lifeExp)
qdiff6(z)
qdiff6(z, na.rm = FALSE)
```

### The useful but mysterious `...` argument

You probably could have lived a long and happy life without knowing there are at least 9 different algorithms for computing quantiles. [Go read about the `type` argument](http://www.rdocumentation.org/packages/stats/functions/quantile) of `quantile()`. TLDR: If a quantile is not unambiguously equal to an observed data point, you must somehow average two data points. You can weight this average different ways, depending on the rest of the data, and `type =` controls this.

Let's say we want to give the user of our function the ability to specify how the quantiles are computed, but we want to accomplish with as little fuss as possible. In fact, we don't even want to clutter our function's interface with this! This calls for the very special `...` argument.

```{r}
qdiff7 <- function(x, probs = c(0, 1), na.rm = TRUE, ...) {
  the_quantiles <- quantile(x = x, probs = probs, na.rm = na.rm, ...)
  return(max(the_quantiles) - min(the_quantiles))
}
```

The practical significance of the `type =` argument is vanishly small, so I have to cook up a specific example so you can even detect a difference due to different settings.

```{r}
set.seed(1234)
z <- rnorm(10)
quantile(z, type=1)
quantile(z, type=4)
all.equal(quantile(z, type=1), quantile(z, type=4))
```

Now we can call our function, requesting that quantiles be computed in different ways.

```{r}
qdiff7(z, probs = c(0.25, 0.75), type = 1)
qdiff7(z, probs = c(0.25, 0.75), type = 4)
```

Don't fret about the subtle difference in result. The point here is to marvel at the fact that we have passed `type = 1` through to `quantile()` *even though it was not a formal argument of our own function*.

The special argument `...` is very useful when you want the ability to pass arbitrary arguments down to another function, but without making them formal arguments to your function. This leaves you with a less cluttered function definition and give you great flexibility in the future to specify these arguments or not, depending on context.

You will also encounter the `...` argument in many built-in functions -- read up [on `c()`](http://www.rdocumentation.org/packages/base/functions/c) or [`list()`](http://www.rdocumentation.org/packages/base/functions/list) -- and now you have a better sense of what it does.

### Use `testthat` for formal unit tests

Until now, we've relied on informal tests of our evolving function. If you are going to use a function alot, especially if it is part of a package, it is wise to use formal unit tests.

The [`testthat` package](https://github.com/hadley/testthat) provides excellent facilities for this, with a distinct emphasis on automated unit testing of entire packages. However, we can take it out for a test drive even with our one measly function.

We will construct a test with `test_that()` and, within it, we put one or more *expectations* that check actual against expected results. You simply harden your informal, interactive tests into formal unit tests. Here are some examples of tests and indicative expectations.

```{r}
library(testthat)
test_that('invalid args are detected', {
  expect_error(qdiff7("eggplants are purple"))
  expect_error(qdiff7(iris))
  })
test_that('NA handling works', {
  expect_error(qdiff7(c(1:5, NA), na.rm = FALSE))
  expect_equal(qdiff7(c(1:5, NA)), 4)
})
```

No news is good news! Let's see what test failure would look like. Let's revert to a version of our function that does no `NA` handling, then test for proper `NA` handling. We can watch it fail.

```{r}
qdiff_no_NA <- function(x, probs = c(0, 1)) {
  the_quantiles <- quantile(x = x, probs = probs)
  return(max(the_quantiles) - min(the_quantiles))
}
test_that('NA handling works', {
  expect_that(qdiff_no_NA(c(1:5, NA)), equals(4))
})
```

Similar to the advice to use `assertthat` in data analytical scripts, I recommend you use `testthat` to monitor the behavior of functions you (or others) will use often. If your tests cover the function's important behavior, then you can edit the internals freely. You'll rest easy in the knowledge that, if you broke anything important, the tests will fail and alert you to the problem.

<!--
### Return to `dplyr` SKIP THIS IN FAVOR OF PLYR

```{r}
library(dplyr)
gtbl <- gDat %>% tbl_df
by_continent <- gtbl %>%
  group_by(continent)
by_continent %>% do(data.frame(max(.$lifeExp)))
```

### other content

match.arg()

defaulting to NULL then checking is.null() and take it from there

-->

### Resources

Packages

  * [`assertthat` package](https://github.com/hadley/assertthat)
  * [`ensurer` package](https://github.com/smbache/ensurer)
  * [`testthat` package](https://github.com/hadley/testthat)

Hadley Wickham's forthcoming book [Advanced R]((http://adv-r.had.co.nz)

  * Section on [defensive programming](http://adv-r.had.co.nz/Exceptions-Debugging.html#defensive-programming)
  
Hadley Wickham's forthcoming book [R packages](http://r-pkgs.had.co.nz)

  * [Testing chapter](http://r-pkgs.had.co.nz/tests.html)

  
